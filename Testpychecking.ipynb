{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8682951,"sourceType":"datasetVersion","datasetId":5205510}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prompt: whats the pip install for models.model import\n\n\n!pip install models\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T12:12:45.288079Z","iopub.execute_input":"2024-07-28T12:12:45.288467Z","iopub.status.idle":"2024-07-28T12:12:47.427409Z","shell.execute_reply.started":"2024-07-28T12:12:45.288431Z","shell.execute_reply":"2024-07-28T12:12:47.426421Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting models\n  Using cached models-0.9.3.tar.gz (16 kB)\n  Preparing metadata (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[8 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m Traceback (most recent call last):\n  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-uurxmezn/models_f858f5b19ff34358a3a1c37f500d066c/setup.py\", line 25, in <module>\n  \u001b[31m   \u001b[0m     import models\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-uurxmezn/models_f858f5b19ff34358a3a1c37f500d066c/models/__init__.py\", line 23, in <module>\n  \u001b[31m   \u001b[0m     from base import *\n  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'base'\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n\u001b[?25h","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/NilotpalMaitra/UDA_thermal\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T12:12:50.745061Z","iopub.execute_input":"2024-07-28T12:12:50.745747Z","iopub.status.idle":"2024-07-28T12:12:52.866755Z","shell.execute_reply.started":"2024-07-28T12:12:50.745716Z","shell.execute_reply":"2024-07-28T12:12:52.865749Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Cloning into 'UDA_thermal'...\nremote: Enumerating objects: 65, done.\u001b[K\nremote: Counting objects: 100% (65/65), done.\u001b[K\nremote: Compressing objects: 100% (46/46), done.\u001b[K\nremote: Total 65 (delta 32), reused 25 (delta 13), pack-reused 0\u001b[K\nUnpacking objects: 100% (65/65), 5.72 MiB | 11.42 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nimport os\n\n# Define the source and destination paths\nsrc_path = 'UDA_thermal/models'\ndest_path = 'models'\n\n# Move the 'models' folder to the desired location\nshutil.move(src_path, dest_path)\n\n# Optionally, remove the rest of the cloned repository\nshutil.rmtree('UDA_thermal')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T12:12:54.683817Z","iopub.execute_input":"2024-07-28T12:12:54.684794Z","iopub.status.idle":"2024-07-28T12:12:54.699342Z","shell.execute_reply.started":"2024-07-28T12:12:54.684754Z","shell.execute_reply":"2024-07-28T12:12:54.698478Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch.backends.cudnn as cudnn\nimport torch.utils.data\nfrom torchvision import transforms\n#from dataset.data_loader import GetLoader\nfrom torchvision import datasets\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\n\nimport torchvision.transforms as T\nimport torchvision\ndevice_gpu=0\n\n\n\n\ndef test_(dataset_name, epoch):\n    assert dataset_name in ['source', 'target']\n\n    model_root = os.path.join(\"/kaggle/working/UDA_thermal/UDA_thermal\", 'models')\n   \n\n    cuda = True\n    cudnn.benchmark = True\n    batch_size = 32\n    image_size = 224\n    alpha = 0\n    # Digits and Alpha\n    #'''\n    img_rgb_resized = np.load(\"/kaggle/input/dataset/X_rgb_224.npy\")\n    labels_rgb = np.load(\"/kaggle/input/dataset/Y_rgb_224.npy\")\n    img_th_rot = np.load(\"/kaggle/input/dataset/X_th_224-001.npy\")\n    labels_th = np.load(\"/kaggle/input/dataset/Y_th_224.npy\")\n\n\n    img_rgb_train, img_rgb_test, labels_rgb_train, labels_rgb_test = train_test_split(img_rgb_resized, labels_rgb, test_size=0.1, random_state=42,stratify=labels_rgb)\n\n    img_th_train, img_th_test, labels_th_train, labels_th_test = train_test_split(img_th_rot, labels_th, test_size=0.6, random_state=42,stratify=labels_th)\n    #'''\n    \n    '''\n    img_rgb_train = np.load('/raid/ai21resch11003/DA_HG/dataset_244/train_source.npy')\n    img_rgb_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_source.npy')\n    labels_rgb_train = np.load('/raid/ai21resch11003/DA_HG/dataset_244/train_source_labels.npy')\n    labels_rgb_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_source_labels.npy')\n\n    img_th_train = np.load('/raid/ai21resch11003/DA_HG/dataset_244/train_target.npy')\n    img_th_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_target.npy')\n    labels_th_train = np.load('/raid/ai21resch11003/DA_HG/dataset_244/train_target_labels.npy')\n    labels_th_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_target_labels.npy')\n    #'''\n  \n\n\n   # '''\n    train = torch.utils.data.TensorDataset(torch.from_numpy(img_rgb_train), torch.from_numpy(labels_rgb_train))\n    test = torch.utils.data.TensorDataset(torch.from_numpy(img_rgb_test), torch.from_numpy(labels_rgb_test))\n    train_dataloader_source = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n    test_dataloader_source = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n\n    train_th = torch.utils.data.TensorDataset(torch.from_numpy(img_th_train), torch.from_numpy(labels_th_train))\n    test_th = torch.utils.data.TensorDataset(torch.from_numpy(img_th_test), torch.from_numpy(labels_th_test))\n    train_dataloader_target = torch.utils.data.DataLoader(train_th, batch_size=batch_size, shuffle=True)\n    test_dataloader_target = torch.utils.data.DataLoader(test_th, batch_size=batch_size, shuffle=True)\n\n    if dataset_name == 'source':\n      dataloader= test_dataloader_source\n    elif dataset_name == 'target':\n      dataloader = test_dataloader_target\n\n    \"\"\" training \"\"\"\n\n    my_net = torch.load(os.path.join(\n        model_root, 'mnist_mnistm_model1_epoch_' + str(epoch) + '.pth'\n    ))\n    my_net = my_net.eval()\n\n    if cuda:\n        my_net = my_net.cuda(device_gpu)\n\n    len_dataloader = len(dataloader)\n    data_target_iter = iter(dataloader)\n\n    i = 0\n    n_total = 0\n    n_correct = 0\n\n    while i < len_dataloader:\n\n        # test model using target data\n        data_target = data_target_iter.next()\n        t_img, t_label = data_target\n\n        batch_size = len(t_label)\n\n        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n        class_label = torch.LongTensor(batch_size)\n\n        if cuda:\n            t_img = t_img.cuda(device_gpu)\n            t_label = t_label.cuda(device_gpu)\n            input_img = input_img.cuda(device_gpu)\n            class_label = class_label.cuda(device_gpu)\n\n        input_img.resize_as_(t_img).copy_(t_img)\n        class_label.resize_as_(t_label).copy_(t_label)\n\n        class_output, _ = my_net(input_data=input_img, alpha=alpha)\n        pred = class_output.data.max(1, keepdim=True)[1]\n        n_correct += pred.eq(class_label.data.view_as(pred)).cpu().sum()\n        n_total += batch_size\n\n        i += 1\n\n    accu = n_correct.data.numpy() * 1.0 / n_total\n    print ('epoch: %d, accuracy of the %s dataset: %f' % (epoch, dataset_name, accu))\n    return accu\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T12:12:58.942453Z","iopub.execute_input":"2024-07-28T12:12:58.942829Z","iopub.status.idle":"2024-07-28T12:12:58.964516Z","shell.execute_reply.started":"2024-07-28T12:12:58.942800Z","shell.execute_reply":"2024-07-28T12:12:58.963409Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Call the test_ function with desired parameters\n# Example: test the model on the 'source' dataset at epoch 10\naccuracy = test_('source', 10)\nprint(f'Accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-07-28T12:13:08.309610Z","iopub.execute_input":"2024-07-28T12:13:08.310246Z","iopub.status.idle":"2024-07-28T12:13:11.380412Z","shell.execute_reply.started":"2024-07-28T12:13:08.310206Z","shell.execute_reply":"2024-07-28T12:13:11.379106Z"},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Call the test_ function with desired parameters\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Example: test the model on the 'source' dataset at epoch 10\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtest_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[11], line 74\u001b[0m, in \u001b[0;36mtest_\u001b[0;34m(dataset_name, epoch)\u001b[0m\n\u001b[1;32m     70\u001b[0m   dataloader \u001b[38;5;241m=\u001b[39m test_dataloader_target\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" training \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m my_net \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnist_mnistm_model1_epoch_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     76\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m my_net \u001b[38;5;241m=\u001b[39m my_net\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cuda:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/UDA_thermal/UDA_thermal/models/mnist_mnistm_model1_epoch_10.pth'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/UDA_thermal/UDA_thermal/models/mnist_mnistm_model1_epoch_10.pth'","output_type":"error"}]}]}