{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"id":"B0l6lMm0AYiJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MAIN.PY","metadata":{"id":"MmkL78g2AZCR"}},{"cell_type":"code","source":"# prompt: whats the pip install for models.model import\n\n\n!pip install models\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pPnZfCeAbpk","outputId":"28a37693-b3f6-4683-d9bf-ad031567b144","execution":{"iopub.status.busy":"2024-06-13T12:49:21.976633Z","iopub.execute_input":"2024-06-13T12:49:21.977390Z","iopub.status.idle":"2024-06-13T12:49:25.136876Z","shell.execute_reply.started":"2024-06-13T12:49:21.977349Z","shell.execute_reply":"2024-06-13T12:49:25.135582Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting models\n  Downloading models-0.9.3.tar.gz (16 kB)\n  Preparing metadata (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[8 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m Traceback (most recent call last):\n  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-s2dao_py/models_64625b04f67a44268c2ff37d8b8a7967/setup.py\", line 25, in <module>\n  \u001b[31m   \u001b[0m     import models\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-s2dao_py/models_64625b04f67a44268c2ff37d8b8a7967/models/__init__.py\", line 23, in <module>\n  \u001b[31m   \u001b[0m     from base import *\n  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'base'\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n\u001b[?25h","output_type":"stream"}]},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount(\"/content/drive\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aBkyCVQGRpvJ","outputId":"93f7e431-d83c-4aac-9611-da589b2a88d4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"}]},{"cell_type":"code","source":"!pwd\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LZbW925MSqGm","outputId":"95ff2216-69e5-44e0-e6c6-377443906159"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"/content\n"}]},{"cell_type":"code","source":"!ls /content/drive/MyDrive/Hand Gesture dataset\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yMKMfVcKS5Cm","outputId":"61e074d6-afb3-4c4f-9f0b-243981963002"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"ls: cannot access '/content/drive/MyDrive/Hand': No such file or directory\n\nls: cannot access 'Gesture': No such file or directory\n\nls: cannot access 'dataset': No such file or directory\n"}]},{"cell_type":"code","source":"import numpy as np\n\n# Load .npy files\nX_rgb_224 = np.load(\"/kaggle/input/dataset/X_rgb_224.npy\")\nX_th_224 = np.load(\"/kaggle/input/dataset/X_th_224-001.npy\")\nY_rgb_224 = np.load(\"/kaggle/input/dataset/Y_rgb_224.npy\")\nY_th_224 = np.load(\"/kaggle/input/dataset/Y_th_224.npy\")\n\n","metadata":{"id":"37ja35ugUKpT","execution":{"iopub.status.busy":"2024-06-13T12:50:00.765224Z","iopub.execute_input":"2024-06-13T12:50:00.766203Z","iopub.status.idle":"2024-06-13T12:50:02.438466Z","shell.execute_reply.started":"2024-06-13T12:50:00.766154Z","shell.execute_reply":"2024-06-13T12:50:02.437498Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# prompt: to know the path of the dataset\n\nimport os\n\n# Get the current working directory\ncwd = os.getcwd()\n\n# Print the path to the dataset\nprint(os.path.join(cwd, 'dataset'))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N5hGzW6jCWuL","outputId":"fd373c8b-8fb9-4e56-b898-e06b5576b47d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"/content/UDA_thermal/UDA_thermal/dataset\n"}]},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Define the file name and the extraction path\nzip_file = '/content/UDA_thermal/UDA_thermal/dataset_244-20240608T115816Z-002.zip'\nextract_path = 'extracted_files'\n\n# Create the extraction path if it doesn't exist\nif not os.path.exists(extract_path):\n    os.makedirs(extract_path)\n\n# Unzip the file\nwith zipfile.ZipFile(zip_file, 'r') as zip_ref:\n    zip_ref.extractall(extract_path)\n\nprint(f\"Files extracted to {extract_path}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oa1ayTp2L74Y","outputId":"853d6ea8-3dcf-405f-cfbe-03d7c428664d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Files extracted to extracted_files\n"}]},{"cell_type":"code","source":"os.listdir()\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oLtDOwT3MuhM","outputId":"1471d1ad-c849-4cef-d482-e851e15d5576"},"execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":["['mnist_mnistm_model1_epoch_192_best_digit.pth',\n"," 'dataset_244-20240608T115816Z-002.zip',\n"," 'tsne.py',\n"," 'README.md',\n"," '__pycache__',\n"," 'models',\n"," 'test_script.py',\n"," 'extracted_files',\n"," 'main.py',\n"," '.git',\n"," 'prec_recall.py']"]},"metadata":{}}]},{"cell_type":"markdown","source":"function.py\n","metadata":{"id":"aHqlZBpJNV-Q"}},{"cell_type":"code","source":"from torch.autograd import Function\n\n\nclass ReverseLayerF(Function):\n\n    @staticmethod\n    def forward(ctx, x, alpha):\n        ctx.alpha = alpha\n\n        return x.view_as(x)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        output = grad_output.neg() * ctx.alpha\n\n        return output, None","metadata":{"id":"SQ1wHdigNSgn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model.py","metadata":{"id":"ZYkzgS9wymsA"}},{"cell_type":"code","source":"!git clone https://github.com/qwedaq/UDA_thermal.git\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gElI9CAuyulR","outputId":"750aa1b3-c3c8-4d5b-b1e3-6731711f14b1","execution":{"iopub.status.busy":"2024-06-13T12:50:16.356135Z","iopub.execute_input":"2024-06-13T12:50:16.356471Z","iopub.status.idle":"2024-06-13T12:50:18.865499Z","shell.execute_reply.started":"2024-06-13T12:50:16.356445Z","shell.execute_reply":"2024-06-13T12:50:18.864190Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Cloning into 'UDA_thermal'...\nremote: Enumerating objects: 30, done.\u001b[K\nremote: Counting objects: 100% (30/30), done.\u001b[K\nremote: Compressing objects: 100% (24/24), done.\u001b[K\nremote: Total 30 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (30/30), 5.71 MiB | 9.87 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd UDA_thermal\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m38qFZ87t3El","outputId":"3c009329-41de-49dd-c858-1fbf902706d1","execution":{"iopub.status.busy":"2024-06-13T12:50:21.739520Z","iopub.execute_input":"2024-06-13T12:50:21.739903Z","iopub.status.idle":"2024-06-13T12:50:21.746665Z","shell.execute_reply.started":"2024-06-13T12:50:21.739871Z","shell.execute_reply":"2024-06-13T12:50:21.745626Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working/UDA_thermal\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"3Q5S-uX_ZPvP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from models.model import CNNModel\n","metadata":{"id":"LK2harXKt67E","execution":{"iopub.status.busy":"2024-06-13T12:50:25.094494Z","iopub.execute_input":"2024-06-13T12:50:25.094891Z","iopub.status.idle":"2024-06-13T12:50:30.464980Z","shell.execute_reply.started":"2024-06-13T12:50:25.094842Z","shell.execute_reply":"2024-06-13T12:50:30.464091Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!ls\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iiXvSh4KvGVJ","outputId":"68f283e1-f995-49a8-a6c0-99a461dd02b8","execution":{"iopub.status.busy":"2024-06-13T12:50:38.188099Z","iopub.execute_input":"2024-06-13T12:50:38.188669Z","iopub.status.idle":"2024-06-13T12:50:39.243570Z","shell.execute_reply.started":"2024-06-13T12:50:38.188636Z","shell.execute_reply":"2024-06-13T12:50:39.242412Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"README.md\t\t\t\t      models\t      tsne.py\nmain.py\t\t\t\t\t      prec_recall.py\nmnist_mnistm_model1_epoch_192_best_digit.pth  test.py\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"dZsrSo6svu8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1W7KK5RCvfY6","outputId":"95dae961-8ba2-4e1d-9b4a-2b978c39eda4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n\n\u001b[0m"}]},{"cell_type":"code","source":"!mv test.py test_script.py\n","metadata":{"id":"mnwQ-NQcvvl5","execution":{"iopub.status.busy":"2024-06-13T12:50:43.386801Z","iopub.execute_input":"2024-06-13T12:50:43.387213Z","iopub.status.idle":"2024-06-13T12:50:44.463671Z","shell.execute_reply.started":"2024-06-13T12:50:43.387173Z","shell.execute_reply":"2024-06-13T12:50:44.461806Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from test_script import test_","metadata":{"id":"pfi66SNEvIta","execution":{"iopub.status.busy":"2024-06-13T12:50:48.253746Z","iopub.execute_input":"2024-06-13T12:50:48.254192Z","iopub.status.idle":"2024-06-13T12:50:49.026854Z","shell.execute_reply.started":"2024-06-13T12:50:48.254156Z","shell.execute_reply":"2024-06-13T12:50:49.025746Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T12:58:03.872723Z","iopub.execute_input":"2024-06-13T12:58:03.873773Z","iopub.status.idle":"2024-06-13T12:58:19.073026Z","shell.execute_reply.started":"2024-06-13T12:58:03.873732Z","shell.execute_reply":"2024-06-13T12:58:19.071911Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport os\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\n#from dataset.data_loader import GetLoader\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom models.model import CNNModel\nimport numpy as np\nfrom test_script import test_\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom torchsummary import summary\nimport warnings\nimport torch\nimport torchvision.transforms as T\nimport torchvision\n\n# Set device GPU\ndevice_gpu = 0\n\nwarnings.filterwarnings(\"ignore\")\nsource_dataset_name = 'source'\ntarget_dataset_name = 'target'\n\n# Set model root directory\nmodel_root = os.path.join(\"/content/UDA_thermal/models\", 'models')  # Update this path to your model directory\ncuda = True\ncudnn.benchmark = True\nlr = 1e-3\nbatch_size = 32\nimage_size = 224\nn_epoch = 200\n\nmanual_seed = random.randint(1, 10000)\nrandom.seed(manual_seed)\ntorch.manual_seed(manual_seed)\n\n# Load data\nimg_rgb_resized = np.load(\"/kaggle/input/dataset/X_rgb_224.npy\")  # Update this path to your RGB resized images\nlabels_rgb = np.load(\"/kaggle/input/dataset/Y_rgb_224.npy\")  # Update this path to your RGB labels\nimg_th_rot = np.load(\"/kaggle/input/dataset/X_th_224-001.npy\")  # Update this path to your thermal rotated images\nlabels_th = np.load(\"/kaggle/input/dataset/Y_th_224.npy\")  # Update this path to your thermal labels\n\n# Split data into train and test sets\nimg_rgb_train, img_rgb_test, labels_rgb_train, labels_rgb_test = train_test_split(\n    img_rgb_resized, labels_rgb, test_size=0.1, random_state=42, stratify=labels_rgb)\n\nimg_th_train, img_th_test, labels_th_train, labels_th_test = train_test_split(\n    img_th_rot, labels_th, test_size=0.6, random_state=42, stratify=labels_th)\n\n# Create TensorDatasets\ntrain = torch.utils.data.TensorDataset(torch.from_numpy(img_rgb_train), torch.from_numpy(labels_rgb_train).squeeze(-1))\ntest = torch.utils.data.TensorDataset(torch.from_numpy(img_rgb_test), torch.from_numpy(labels_rgb_test).squeeze(-1))\ntrain_dataloader_source = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\ntest_dataloader_source = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n\ntrain_th = torch.utils.data.TensorDataset(torch.from_numpy(img_th_train), torch.from_numpy(labels_th_train).squeeze(-1))\ntest_th = torch.utils.data.TensorDataset(torch.from_numpy(img_th_test), torch.from_numpy(labels_th_test).squeeze(-1))\ntrain_dataloader_target = torch.utils.data.DataLoader(train_th, batch_size=batch_size, shuffle=True)\ntest_dataloader_target = torch.utils.data.DataLoader(test_th, batch_size=batch_size, shuffle=True)\n\ndataloader_source = train_dataloader_source\ndataloader_target = train_dataloader_target\n\nmy_net = CNNModel()\n\n# Setup optimizer\noptimizer = optim.Adam(my_net.parameters(), lr=lr)\n\nloss_class = torch.nn.NLLLoss()\nloss_domain = torch.nn.NLLLoss()\n\nif cuda:\n    my_net = my_net.cuda(device_gpu)\n    loss_class = loss_class.cuda(device_gpu)\n    loss_domain = loss_domain.cuda(device_gpu)\n\n# Training\nsrc_err = []\nsrc_d_err = []\ntgt_d_err = []\n\nsource_accu = []\ntarget_accu = []\n\nfor epoch in range(n_epoch):\n    len_dataloader = min(len(dataloader_source), len(dataloader_target))\n    data_source_iter = iter(dataloader_source)\n    data_target_iter = iter(dataloader_target)\n\n    i = 0\n    while i < len_dataloader:\n        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n\n        # Training model using source data\n        data_source = next(data_source_iter)\n        s_img, s_label = data_source\n\n        my_net.zero_grad()\n        batch_size = len(s_label)\n\n        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n        class_label = torch.LongTensor(batch_size)\n        domain_label = torch.zeros(batch_size)\n        domain_label = domain_label.long()\n\n        if cuda:\n            s_img = s_img.cuda(device_gpu)\n            s_label = s_label.cuda(device_gpu)\n            input_img = input_img.cuda(device_gpu)\n            class_label = class_label.cuda(device_gpu)\n            domain_label = domain_label.cuda(device_gpu)\n\n        input_img.resize_as_(s_img).copy_(s_img)\n        class_label.resize_as_(s_label).copy_(s_label)\n\n        class_output, domain_output = my_net(input_data=input_img, alpha=alpha)\n\n        err_s_label = loss_class(class_output, class_label)\n        err_s_domain = loss_domain(domain_output, domain_label)\n\n        # Training model using target data\n        data_target = next(data_target_iter)\n        t_img, _ = data_target\n\n        batch_size = len(t_img)\n\n        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n        domain_label = torch.ones(batch_size)\n        domain_label = domain_label.long()\n\n        if cuda:\n            t_img = t_img.cuda(device_gpu)\n            input_img = input_img.cuda(device_gpu)\n            domain_label = domain_label.cuda(device_gpu)\n\n        input_img.resize_as_(t_img).copy_(t_img)\n\n        _, domain_output = my_net(input_data=input_img, alpha=alpha)\n        err_t_domain = loss_domain(domain_output, domain_label)\n        err = err_t_domain + err_s_domain + err_s_label\n        err.backward()\n        optimizer.step()\n\n        i += 1\n\n    src_err.append(err_s_label.cpu().data.numpy())\n    src_d_err.append(err_s_domain.cpu().data.numpy())\n    tgt_d_err.append(err_t_domain.cpu().data.numpy())\n    torch.save(my_net, '{0}/mnist_mnistm_model1_epoch_{1}.pth'.format('/content/UDA_thermal/models', epoch))  # Update this path to your model directory\n    source_accu.append(test_(source_dataset_name, epoch))\n    target_accu.append(test_(target_dataset_name, epoch))\n\nplt.plot(np.arange(0, n_epoch, 1), np.array(source_accu), label='Source Classification Accuracy')\nplt.plot(np.arange(0, n_epoch, 1), np.array(target_accu), label='Target Classification Accuracy')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.savefig('/kaggle/working/output.png')  # Update this path to your output file\n\nprint('done')\n","metadata":{"id":"cklcGqzXAO16","execution":{"iopub.status.busy":"2024-06-13T13:03:35.932997Z","iopub.execute_input":"2024-06-13T13:03:35.933476Z","iopub.status.idle":"2024-06-13T13:03:39.895357Z","shell.execute_reply.started":"2024-06-13T13:03:35.933443Z","shell.execute_reply":"2024-06-13T13:03:39.893832Z"},"trusted":true},"execution_count":18,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 120\u001b[0m\n\u001b[1;32m    117\u001b[0m input_img\u001b[38;5;241m.\u001b[39mresize_as_(s_img)\u001b[38;5;241m.\u001b[39mcopy_(s_img)\n\u001b[1;32m    118\u001b[0m class_label\u001b[38;5;241m.\u001b[39mresize_as_(s_label)\u001b[38;5;241m.\u001b[39mcopy_(s_label)\n\u001b[0;32m--> 120\u001b[0m class_output, domain_output \u001b[38;5;241m=\u001b[39m \u001b[43mmy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m err_s_label \u001b[38;5;241m=\u001b[39m loss_class(class_output, class_label)\n\u001b[1;32m    123\u001b[0m err_s_domain \u001b[38;5;241m=\u001b[39m loss_domain(domain_output, domain_label)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/kaggle/working/UDA_thermal/models/model.py:190\u001b[0m, in \u001b[0;36mCNNModel.forward\u001b[0;34m(self, input_data, alpha)\u001b[0m\n\u001b[1;32m    188\u001b[0m reverse_feature \u001b[38;5;241m=\u001b[39m ReverseLayerF\u001b[38;5;241m.\u001b[39mapply(feature, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    189\u001b[0m class_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_classifier(feature)\n\u001b[0;32m--> 190\u001b[0m domain_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreverse_feature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m#print(class_output.shape)\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m class_output, domain_output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x256 and 2048x100)"],"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (32x256 and 2048x100)","output_type":"error"}]},{"cell_type":"markdown","source":"Prec.recall.py","metadata":{"id":"6oOLqNVWBA4L"}},{"cell_type":"code","source":"\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nbatch_size=1\ncuda=True\ndevice_gpu=1\nimage_size = 224\nalpha=0\nmy_net = torch.load(\"/raid/ai21resch11003/DA_HG/mnist_mnistm_model1_epoch_192_best_digit.pth\")\nmy_net = my_net.eval()\n'''\nimg_rgb_resized = np.load(\"/raid/ai21resch11003/DA_HG/comb_data/X_rgb_224.npy\")\nlabels_rgb = np.load(\"/raid/ai21resch11003/DA_HG/comb_data/Y_rgb_224.npy\")\nimg_th_rot = np.load(\"/raid/ai21resch11003/DA_HG/comb_data/X_th_224-002.npy\")\nlabels_th = np.load(\"/raid/ai21resch11003/DA_HG/comb_data/Y_th_224.npy\")\n\n\n\nimg_rgb_train, img_rgb_test, labels_rgb_train, labels_rgb_test = train_test_split(img_rgb_resized, labels_rgb, test_size=0.1, random_state=42,stratify=labels_rgb)\n\nimg_th_train, img_th_test, labels_th_train, labels_th_test = train_test_split(img_th_rot, labels_th, test_size=0.6, random_state=42,stratify=labels_th)\n'''\n\nimg_th_train = np.load('/raid/ai21resch11003/DA_HG/dataset_244/train_target.npy')\nimg_th_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_target.npy')\nlabels_th_train = np.load('/raid/ai21resch11003/DA_HG/dataset_244/train_target_labels.npy')\nlabels_th_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_target_labels.npy')\n\ntrain_th = torch.utils.data.TensorDataset(torch.from_numpy(img_th_train), torch.from_numpy(labels_th_train))\ntest_th = torch.utils.data.TensorDataset(torch.from_numpy(img_th_test), torch.from_numpy(labels_th_test))\ntrain_dataloader_target = torch.utils.data.DataLoader(train_th, batch_size=batch_size, shuffle=True)\ntest_dataloader_target = torch.utils.data.DataLoader(test_th, batch_size=batch_size, shuffle=True)\n\nif cuda:\n    my_net = my_net.cuda(device_gpu)\n\nlen_dataloader = len(test_dataloader_target)\ndata_target_iter = iter(test_dataloader_target)\n\ni = 0\nn_total = 0\nn_correct = 0\npred_ = []\ngt_=[]\nwhile i < len_dataloader:\n\n    # test model using target data\n    data_target = data_target_iter.next()\n    t_img, t_label = data_target\n\n    batch_size = len(t_label)\n\n    input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n    class_label = torch.LongTensor(batch_size)\n\n    if cuda:\n        t_img = t_img.cuda(device_gpu)\n        t_label = t_label.cuda(device_gpu)\n        input_img = input_img.cuda(device_gpu)\n        class_label = class_label.cuda(device_gpu)\n\n    input_img.resize_as_(t_img).copy_(t_img)\n    class_label.resize_as_(t_label).copy_(t_label)\n\n    class_output, _ = my_net(input_data=input_img, alpha=alpha)\n    pred = class_output.data.max(1, keepdim=True)[1]\n    n_correct += pred.eq(class_label.data.view_as(pred)).cpu().sum()\n    n_total += batch_size\n    pred_.append(pred.cpu().numpy())\n    gt_.append(class_label.cpu().numpy())\n\n    i += 1\n\naccu = n_correct.data.numpy() * 1.0 / n_total\nprint ('accuracy :'+str(accu))\ntemp = np.squeeze(pred_,axis=-1)\ntemp_ = np.array(gt_)\nprint(temp_.shape)\nprint(temp.shape)\n\n#pred = model(img_th_test,1.0)\nprecision = precision_score(np.squeeze(temp_,axis=-1), np.squeeze(temp,axis=-1),average='micro')\nrecall = recall_score(np.squeeze(temp_,axis=-1), np.squeeze(temp,axis=-1),average='micro')\nclass_rep = classification_report(np.squeeze(temp_,axis=-1), np.squeeze(temp,axis=-1))\nprint('Precision: ',precision)\nprint('Recall: ',recall)\nprint(class_rep)\n","metadata":{"id":"dHgXwkfeA_wX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test.py","metadata":{"id":"x2U29QVYAoEv"}},{"cell_type":"code","source":"import random\nimport os\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\n#from dataset.data_loader import GetLoader\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom models.model import CNNModel\nimport numpy as np\nfrom test import test_\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom torchsummary import summary\nimport warnings\nimport torch\nimport torchvision.transforms as T\nimport torchvision\n#export CUDA_VISIBLE_DEVICES=4\ndevice_gpu =0\n\n\n\n\nwarnings.filterwarnings(\"ignore\")\nsource_dataset_name = 'source'\ntarget_dataset_name = 'target'\n\nmodel_root = os.path.join(\"/raid/ai21resch11003/DA_HG/\", 'models')\ncuda = True\ncudnn.benchmark = True\nlr = 1e-3\nbatch_size = 32\nimage_size = 224\nn_epoch = 200\n\nmanual_seed = random.randint(1, 10000)\nrandom.seed(manual_seed)\ntorch.manual_seed(manual_seed)\n#\n# load data\n\n\n# DIgits and Alpha\n#'''\nimg_rgb_resized = np.load(\"/raid/ai21resch11003/DA_HG/comb_data/X_rgb_224.npy\")\nlabels_rgb = np.load(\"/raid/ai21resch11003/DA_HG/comb_data/Y_rgb_224.npy\")\n#img_rgb_resized = np.transpose(img_rgb_resized,(0,-1,1,2))\nimg_th_rot = np.load(\"/raid/ai21resch11003/DA_HG/comb_data/X_th_224-002.npy\")\nlabels_th = np.load(\"/raid/ai21resch11003/DA_HG/comb_data/Y_th_224.npy\")\n#img_th_rot = np.transpose(img_th_rot,(0,-1,1,2))\n\nimg_rgb_train, img_rgb_test, labels_rgb_train, labels_rgb_test = train_test_split(img_rgb_resized, labels_rgb, test_size=0.1, random_state=42,stratify=labels_rgb)\n\nimg_th_train, img_th_test, labels_th_train, labels_th_test = train_test_split(img_th_rot, labels_th, test_size=0.6, random_state=42,stratify=labels_th)\n#'''\n'''\nimg_rgb_train = np.load('/raid/ai21resch11003/DA_HG/dataset_244/train_source.npy')\nimg_rgb_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_source.npy')\nlabels_rgb_train = np.load('/raid/ai21resch11003/DA_HG/dataset_244/train_source_labels.npy')\nlabels_rgb_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_source_labels.npy')\n\nimg_th_train = np.load('/raid/ai21resch11003/DA_HG/dataset_244/train_target.npy')\nimg_th_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_target.npy')\nlabels_th_train = np.load('/raid/ai21resch11003/DA_HG/dataset_244/train_target_labels.npy')\nlabels_th_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_target_labels.npy')\n#'''\n#'''\ntrain = torch.utils.data.TensorDataset(torch.from_numpy(img_rgb_train), torch.from_numpy(labels_rgb_train).squeeze(-1))\ntest = torch.utils.data.TensorDataset(torch.from_numpy(img_rgb_test), torch.from_numpy(labels_rgb_test).squeeze(-1))\ntrain_dataloader_source = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\ntest_dataloader_source = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n\ntrain_th = torch.utils.data.TensorDataset(torch.from_numpy(img_th_train), torch.from_numpy(labels_th_train).squeeze(-1))\ntest_th = torch.utils.data.TensorDataset(torch.from_numpy(img_th_test), torch.from_numpy(labels_th_test).squeeze(-1))\ntrain_dataloader_target = torch.utils.data.DataLoader(train_th, batch_size=batch_size, shuffle=True)\ntest_dataloader_target = torch.utils.data.DataLoader(test_th, batch_size=batch_size, shuffle=True)\n#'''\n\n\n\n\n\ndataloader_source = train_dataloader_source\ndataloader_target = train_dataloader_target\n\nmy_net = CNNModel()\n\n# setup optimizer\n\noptimizer = optim.Adam(my_net.parameters(), lr=lr)\n\nloss_class = torch.nn.NLLLoss()\nloss_domain = torch.nn.NLLLoss()\n\nif cuda:\n    my_net = my_net.cuda(device_gpu)\n    loss_class = loss_class.cuda(device_gpu)\n    loss_domain = loss_domain.cuda(device_gpu)\n\n\n\n# training\nsrc_err=[]\nsrc_d_err=[]\ntgt_d_err=[]\n\nsource_accu=[]\ntarget_accu=[]\n\nfor epoch in range(n_epoch):\n\n    len_dataloader = min(len(dataloader_source), len(dataloader_target))\n    data_source_iter = iter(dataloader_source)\n    data_target_iter = iter(dataloader_target)\n\n    i = 0\n    while i < len_dataloader:\n\n        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n\n        # training model using source data\n        data_source = data_source_iter.next()\n        s_img, s_label = data_source\n\n        my_net.zero_grad()\n        batch_size = len(s_label)\n\n        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n        class_label = torch.LongTensor(batch_size)\n        domain_label = torch.zeros(batch_size)\n        domain_label = domain_label.long()\n\n        if cuda:\n            s_img = s_img.cuda(device_gpu)\n            s_label = s_label.cuda(device_gpu)\n            input_img = input_img.cuda(device_gpu)\n            class_label = class_label.cuda(device_gpu)\n            domain_label = domain_label.cuda(device_gpu)\n\n        input_img.resize_as_(s_img).copy_(s_img)\n        class_label.resize_as_(s_label).copy_(s_label)\n        #print(input_img.shape)\n        #print(class_label.shape)\n        class_output, domain_output = my_net(input_data=input_img, alpha=alpha)\n\n        err_s_label = loss_class(class_output, class_label)\n        err_s_domain = loss_domain(domain_output, domain_label)\n\n        # training model using target data\n        data_target = data_target_iter.next()\n        t_img, _ = data_target\n\n        batch_size = len(t_img)\n\n        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n        domain_label = torch.ones(batch_size)\n        domain_label = domain_label.long()\n\n        if cuda:\n            t_img = t_img.cuda(device_gpu)\n            input_img = input_img.cuda(device_gpu)\n            domain_label = domain_label.cuda(device_gpu)\n\n        input_img.resize_as_(t_img).copy_(t_img)\n\n        _, domain_output = my_net(input_data=input_img, alpha=alpha)\n        err_t_domain = loss_domain(domain_output, domain_label)\n        err = err_t_domain + err_s_domain + err_s_label\n        err.backward()\n        optimizer.step()\n\n        i += 1\n\n       #print ('epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n              #% (epoch, i, len_dataloader, err_s_label.cpu().data.numpy(),\n                 #err_s_domain.cpu().data.numpy(), err_t_domain.cpu().data.numpy()))\n    #print(model_root)\n    src_err.append(err_s_label.cpu().data.numpy())\n    src_d_err.append(err_s_domain.cpu().data.numpy())\n    tgt_d_err.append(err_t_domain.cpu().data.numpy())\n    torch.save(my_net, '{0}/mnist_mnistm_model1_epoch_{1}.pth'.format('/raid/ai21resch11003/DA_HG/models/', epoch))\n    source_accu.append(test_(source_dataset_name, epoch))\n    target_accu.append(test_(target_dataset_name, epoch))\n\n#plt.plot(np.arange(0,n_epoch,1),np.array(src_err),label='Classification Error')\n#plt.xlabel(\"Epochs\")\n#plt.ylabel(\"Error\")\n#plt.title(\"Source Classification Error\")\n#plt.legend()\n#plt.savefig('/content/drive/MyDrive/DANN/err1.png')\n#plt.show()\n\n#plt.plot(np.arange(0,n_epoch,1),np.array(src_d_err),label='Source Classification Error')\n\n#plt.plot(np.arange(0,n_epoch,1),np.array(tgt_d_err),label='Target Classification Error')\n\n#plt.legend()\n#plt.savefig('/raid/ai21resch11003/DA_HG/err_alex1.png')\n#plt.show()\n\nplt.plot(np.arange(0,n_epoch,1),np.array(source_accu),label='Source Classification Accuracy')\nplt.plot(np.arange(0,n_epoch,1),np.array(target_accu),label='Target Classification Accuracy')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.savefig('/raid/ai21resch11003/DA_HG/acc_alex_cbam_digit_final_.png')\n\nprint ('done')","metadata":{"id":"idDRx38tAmir"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tsne.py","metadata":{"id":"j8fkquAIBJBo"}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndevice_gpu=0\nbatch_size = 1\n\n'''\nimg_th_rot = np.load(\"/raid/ai21resch11003/DA_HG/comb_data/X_th_224-002.npy\")\nlabels_th = np.load(\"/raid/ai21resch11003/DA_HG/comb_data/Y_th_224.npy\")\n\nimg_th_train, img_th_test, labels_th_train, labels_th_test = train_test_split(img_th_rot, labels_th, test_size=0.6, random_state=42,stratify=labels_th)\n\nimg_rgb_rot = np.load(\"/raid/ai21resch11003/DA_HG/comb_data/X_rgb_224.npy\")\nlabels_rgb = np.load(\"/raid/ai21resch11003/DA_HG/comb_data/Y_rgb_224.npy\")\n\nimg_rgb_train, img_rgb_test, labels_rgb_train, labels_rgb_test = train_test_split(img_rgb_rot, labels_rgb, test_size=0.1, random_state=42,stratify=labels_rgb)\n'''\n#---- Digits Dataset path------#\nimg_th_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_target.npy')\nlabels_th_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_target_labels.npy')\n\nimg_rgb_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_source.npy')\nlabels_rgb_test = np.load('/raid/ai21resch11003/DA_HG/dataset_244/test_source_labels.npy')\n#'''\n\ntest_th = torch.utils.data.TensorDataset(torch.from_numpy(img_th_test), torch.from_numpy(labels_th_test))\ntest_dataloader_target = torch.utils.data.DataLoader(test_th, batch_size=batch_size, shuffle=True)\n\ntest_rgb = torch.utils.data.TensorDataset(torch.from_numpy(img_rgb_test), torch.from_numpy(labels_rgb_test))\ntest_dataloader_source = torch.utils.data.DataLoader(test_rgb, batch_size=batch_size, shuffle=True)\n\n#---- Alexnet model path------#\nmodel = torch.load(\"/raid/ai21resch11003/DA_HG/models/mnist_mnistm_model1_epoch_66.pth\")\n\nmodel = model.eval()\n\nactivation = {}\ndef get_activation(name):\n    def hook(model, input, output):\n        activation[name] = output.detach()\n    return hook\n\n#x = torch.rand(1,3,224,224).cuda(device_gpu)\ni = 0\nn_total = 0\nn_correct = 0\n\ndata_target_iter = iter(test_dataloader_target)\nlen_dataloader = len(test_dataloader_target)\n#print(\"Length of the dataloadetr:\" +str(len_dataloader))\n\nbottleneck = np.empty((len_dataloader, 256)) #256 for digit 128*4*4 for aplha\nlabels_numpy = np.empty((len_dataloader,1))\n\nwhile i < len_dataloader:\n  data_target = data_target_iter.next()\n  t_img, t_label = data_target\n  t_img = t_img.type(torch.FloatTensor).cuda(device_gpu)\n  t_label = t_label.type(torch.LongTensor).cuda(device_gpu)\n\n  #print(t_img.shape)\n  batch_size = len(t_label)\n\n  model.max3.register_forward_hook(get_activation('max3'))\n  class_output, _ = model(input_data=t_img, alpha=1.0)\n\n  bottleneck[i] = activation['max3'].view(-1, 256)[0].cpu().numpy() #256 for digit 128*4*4 for alpha\n  labels_numpy[i] = t_label.cpu().numpy()\n\n  pred = class_output.data.max(1, keepdim=True)[1]\n  n_correct += pred.eq(t_label.data.view_as(pred)).cpu().sum()\n  n_total += batch_size\n\n  i += 1\n\naccu = n_correct.data.numpy() * 1.0 / n_total\nprint ('epoch: %d, accuracy of the %s dataset: %f' % (1, 'target', accu))\nprint(bottleneck.shape)\n#print(labels_numpy)\n\n## Source\n\ni = 0\nn_total = 0\nn_correct = 0\n\ndata_source_iter = iter(test_dataloader_source)\nlen_dataloader_source = len(test_dataloader_source)\n#print(\"Length of the dataloadetr:\" +str(len_dataloader))\n\nbottleneck_source = np.empty((len_dataloader_source, 256)) #256 for digit\nlabels_numpy_source = np.empty((len_dataloader_source,1))\n\nwhile i < len_dataloader_source:\n  data_source = data_source_iter.next()\n  t_img, t_label = data_source\n  t_img = t_img.type(torch.FloatTensor).cuda(device_gpu)\n  t_label = t_label.type(torch.LongTensor).cuda(device_gpu)\n\n  batch_size = len(t_label)\n\n  model.max3.register_forward_hook(get_activation('max3'))\n  class_output, _ = model(input_data=t_img, alpha=1.0)\n\n  bottleneck_source[i] = activation['max3'].view(-1, 256)[0].cpu().numpy()\n  labels_numpy_source[i] = t_label.cpu().numpy()\n\n  pred = class_output.data.max(1, keepdim=True)[1]\n  n_correct += pred.eq(t_label.data.view_as(pred)).cpu().sum()\n  n_total += batch_size\n\n  i += 1\n\naccu_source = n_correct.data.numpy() * 1.0 / n_total\nprint ('epoch: %d, accuracy of the %s dataset: %f' % (1, 'source', accu_source))\nprint(bottleneck_source.shape)\n\nfor i in range(labels_numpy_source.shape[0]):\n  labels_numpy_source[i] += 10\n#print(labels_numpy_source)\n\nbottleneck_f = np.append(bottleneck,bottleneck_source,axis=0)\nlabels_numpy_f = np.append(labels_numpy,labels_numpy_source,axis=0)\n\ntsne = TSNE(n_components=2, verbose=1, random_state=123)\nz = tsne.fit_transform(bottleneck_f)\n\ndf = pd.DataFrame()\ndf[\"y\"] = labels_numpy_f[:,0]\ndf[\"comp-1\"] = z[:,0]\ndf[\"comp-2\"] = z[:,1]\n\n'''\ntsne_ = TSNE(n_components=2, verbose=1, random_state=123)\nz_src = tsne_.fit_transform(bottleneck_source)\n\ndf_src = pd.DataFrame()\ndf_src[\"y\"] = labels_numpy_source[:,0]\ndf_src[\"comp-1\"] = z_src[:,0]\ndf_src[\"comp-2\"] = z_src[:,1]\n\ndf_f = df.append(df_src)\n'''\nsns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n                palette=sns.color_palette(\"hls\", 20),\n                data=df).set(title=\"Sign Digits Classification dataset T-SNE projection\")\n#plt.scatter(df['comp-1'],df['comp-2'],color='red',label='Target')\n#plt.scatter(df_src['comp-1'],df_src['comp-2'],color='blue',label='Source')\nplt.legend(loc=(0.985,0))\nplt.savefig('/raid/ai21resch11003/DA_HG/tsne_digit_comb_alex.png')\n\n'''\nmodel.max3.register_forward_hook(get_activation('max3'))\noutput = model(x,alpha=1.0)\nprint(activation['max3'].shape)\n'''","metadata":{"id":"lXXIIyffBHlo"},"execution_count":null,"outputs":[]}]}